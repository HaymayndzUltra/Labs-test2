# ğŸš€ API Testing Automation with One-liner Scripts

## Overview
This setup provides automated API testing with evidence collection using Postman and Newman. Perfect for CI/CD pipelines and quality gates.

## ğŸ“ Project Structure
```
Labs-test2/
â”œâ”€â”€ package.json                    # NPM scripts configuration
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ check-postman.js           # Quality gate checker
â””â”€â”€ clients/
    â””â”€â”€ acme-001/
        â”œâ”€â”€ postman/
        â”‚   â”œâ”€â”€ collection.json     # Postman test collection
        â”‚   â””â”€â”€ env.stage.json     # Stage environment variables
        â””â”€â”€ reports/
            â””â”€â”€ api/               # Test reports and evidence
```

## ğŸ› ï¸ Available Scripts

### 1. Run API Tests (`api:run:stage`)
```bash
npm run api:run:stage
```

**What it does:**
- Runs Postman collection against stage environment
- Generates both CLI and JSON reports
- Saves detailed results to `clients/acme-001/reports/api/postman_stage.json`

**Output:**
- âœ… Real-time test results in terminal
- ğŸ“„ Detailed JSON report for analysis
- â±ï¸ Performance metrics and timing data

### 2. Quality Gate Check (`api:gate`)
```bash
npm run api:gate
```

**What it does:**
- Validates test results from JSON report
- Acts as quality gate (pass/fail)
- Generates evidence file for compliance
- Exits with code 0 (success) or 1 (failure)

**Output:**
- ğŸ“Š Test summary statistics
- âŒ Detailed failure information (if any)
- ğŸ“„ Evidence file for audit trails
- ğŸš« Blocks deployment if tests fail

## ğŸš€ Usage Examples

### Basic Testing
```bash
# Run tests and check results
npm run api:run:stage && npm run api:gate
```

### CI/CD Integration
```yaml
# GitHub Actions example
- name: Run API Tests
  run: npm run api:run:stage

- name: Quality Gate Check
  run: npm run api:gate
```

### Docker Integration
```dockerfile
# Dockerfile example
COPY package.json ./
RUN npm install
COPY clients/ ./clients/
RUN npm run api:run:stage && npm run api:gate
```

## ğŸ“Š Test Results Format

### JSON Report Structure
```json
{
  "run": {
    "stats": {
      "assertions": {
        "total": 9,
        "failed": 0
      }
    },
    "timings": {
      "started": 1234567890,
      "completed": 1234567891
    },
    "failures": []
  }
}
```

### Evidence File
```
Postman Test Evidence
====================
Date: 2024-01-15T10:30:00.000Z
Report: clients/acme-001/reports/api/postman_stage.json
Status: PASSED
Tests: 9
Passed: 9
Failed: 0
Duration: 1000ms
Quality Gate: PASSED
```

## ğŸ”§ Configuration

### Environment Variables
Edit `clients/acme-001/postman/env.stage.json`:
```json
{
  "values": [
    {
      "key": "base_url",
      "value": "https://your-api-stage.com",
      "enabled": true
    },
    {
      "key": "auth_token",
      "value": "your-stage-token",
      "enabled": true
    }
  ]
}
```

### Test Collection
Add your API tests to `clients/acme-001/postman/collection.json`:
- Health checks
- Authentication tests
- CRUD operations
- Performance tests
- Error handling tests

## ğŸ¯ Quality Gate Rules

The quality gate will **FAIL** if:
- âŒ Any test assertions fail
- âŒ Response times exceed thresholds
- âŒ Required fields are missing
- âŒ Status codes are incorrect

The quality gate will **PASS** if:
- âœ… All tests pass
- âœ… Performance requirements met
- âœ… All assertions successful
- âœ… No critical errors

## ğŸš¨ Error Handling

### Common Issues
1. **Report file not found**
   - Ensure `api:run:stage` ran successfully first
   - Check file path in script configuration

2. **Tests failing**
   - Review test assertions in collection
   - Check environment variables
   - Verify API endpoints are accessible

3. **Permission errors**
   - Ensure `tools/check-postman.js` is executable
   - Check write permissions for reports directory

### Debug Mode
```bash
# Run with verbose output
DEBUG=* npm run api:run:stage

# Check specific report file
node tools/check-postman.js clients/acme-001/reports/api/postman_stage.json
```

## ğŸ“ˆ Advanced Features

### Custom Test Thresholds
Modify `tools/check-postman.js` to add custom validation rules:
```javascript
// Add custom performance thresholds
if (responseTime > 5000) {
    console.error('âŒ Response time too slow');
    process.exit(1);
}
```

### Multiple Environments
Add more scripts for different environments:
```json
{
  "scripts": {
    "api:run:dev": "newman run clients/acme-001/postman/collection.json -e clients/acme-001/postman/env.dev.json --reporters cli,json --reporter-json-export clients/acme-001/reports/api/postman_dev.json",
    "api:run:prod": "newman run clients/acme-001/postman/collection.json -e clients/acme-001/postman/env.prod.json --reporters cli,json --reporter-json-export clients/acme-001/reports/api/postman_prod.json"
  }
}
```

### Integration with Other Tools
- **Slack notifications** on test failures
- **Jira ticket creation** for failed tests
- **Email alerts** for critical failures
- **Dashboard updates** with test metrics

## ğŸ‰ Benefits

1. **Automated Testing** - No manual intervention required
2. **Evidence Collection** - Audit trail for compliance
3. **Quality Gates** - Prevents bad deployments
4. **CI/CD Ready** - Integrates with any pipeline
5. **Performance Monitoring** - Tracks response times
6. **Error Detection** - Catches issues early
7. **Team Collaboration** - Shared test results

## ğŸš€ Next Steps

1. **Customize tests** for your specific APIs
2. **Add more environments** (dev, prod, etc.)
3. **Integrate with CI/CD** pipeline
4. **Set up monitoring** and alerts
5. **Expand test coverage** for all endpoints
6. **Add performance benchmarks**
7. **Create test dashboards**

---

**Ready to test! Run `npm run api:run:stage && npm run api:gate` to get started!** ğŸš€
